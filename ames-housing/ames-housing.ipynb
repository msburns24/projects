{
 "cells": [
  {
   "cell_type": "raw",
   "id": "beef8f61",
   "metadata": {},
   "source": [
    "---\n",
    "title: Ames Housing Price Prediction\n",
    "date: 2025-09-05\n",
    "format:\n",
    "  html:\n",
    "    code-fold: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d731573",
   "metadata": {},
   "source": [
    "![Arial View of Housing](housing-header.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b05ebc6",
   "metadata": {},
   "source": [
    "The Ames Housing Dataset is one of the richest and most detailed datasets for\n",
    "house price prediction. It was compiled by Dean De Cock (2009) as a modern\n",
    "replacement for the Boston dataset. With nearly 80 detailed features describing\n",
    "aspects like neighborhood, lot size, and even garage quality, there are plenty\n",
    "of features to work with.\n",
    "\n",
    "The goal of this notebook is to use these features to predict the `SalePrice`,\n",
    "the target of this analysis. As it is a continuous feature we are predicting,\n",
    "we will make use of regression techniques in our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05bb8bc",
   "metadata": {},
   "source": [
    "We'll start by importing some initial modules and taking a preliminary look at\n",
    "our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "066c897e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abddcfb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1460 entries, 1 to 1460\n",
      "Data columns (total 80 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   MSSubClass     1460 non-null   int64  \n",
      " 1   MSZoning       1460 non-null   object \n",
      " 2   LotFrontage    1201 non-null   float64\n",
      " 3   LotArea        1460 non-null   int64  \n",
      " 4   Street         1460 non-null   object \n",
      " 5   Alley          91 non-null     object \n",
      " 6   LotShape       1460 non-null   object \n",
      " 7   LandContour    1460 non-null   object \n",
      " 8   Utilities      1460 non-null   object \n",
      " 9   LotConfig      1460 non-null   object \n",
      " 10  LandSlope      1460 non-null   object \n",
      " 11  Neighborhood   1460 non-null   object \n",
      " 12  Condition1     1460 non-null   object \n",
      " 13  Condition2     1460 non-null   object \n",
      " 14  BldgType       1460 non-null   object \n",
      " 15  HouseStyle     1460 non-null   object \n",
      " 16  OverallQual    1460 non-null   int64  \n",
      " 17  OverallCond    1460 non-null   int64  \n",
      " 18  YearBuilt      1460 non-null   int64  \n",
      " 19  YearRemodAdd   1460 non-null   int64  \n",
      " 20  RoofStyle      1460 non-null   object \n",
      " 21  RoofMatl       1460 non-null   object \n",
      " 22  Exterior1st    1460 non-null   object \n",
      " 23  Exterior2nd    1460 non-null   object \n",
      " 24  MasVnrType     588 non-null    object \n",
      " 25  MasVnrArea     1452 non-null   float64\n",
      " 26  ExterQual      1460 non-null   object \n",
      " 27  ExterCond      1460 non-null   object \n",
      " 28  Foundation     1460 non-null   object \n",
      " 29  BsmtQual       1423 non-null   object \n",
      " 30  BsmtCond       1423 non-null   object \n",
      " 31  BsmtExposure   1422 non-null   object \n",
      " 32  BsmtFinType1   1423 non-null   object \n",
      " 33  BsmtFinSF1     1460 non-null   int64  \n",
      " 34  BsmtFinType2   1422 non-null   object \n",
      " 35  BsmtFinSF2     1460 non-null   int64  \n",
      " 36  BsmtUnfSF      1460 non-null   int64  \n",
      " 37  TotalBsmtSF    1460 non-null   int64  \n",
      " 38  Heating        1460 non-null   object \n",
      " 39  HeatingQC      1460 non-null   object \n",
      " 40  CentralAir     1460 non-null   object \n",
      " 41  Electrical     1459 non-null   object \n",
      " 42  1stFlrSF       1460 non-null   int64  \n",
      " 43  2ndFlrSF       1460 non-null   int64  \n",
      " 44  LowQualFinSF   1460 non-null   int64  \n",
      " 45  GrLivArea      1460 non-null   int64  \n",
      " 46  BsmtFullBath   1460 non-null   int64  \n",
      " 47  BsmtHalfBath   1460 non-null   int64  \n",
      " 48  FullBath       1460 non-null   int64  \n",
      " 49  HalfBath       1460 non-null   int64  \n",
      " 50  BedroomAbvGr   1460 non-null   int64  \n",
      " 51  KitchenAbvGr   1460 non-null   int64  \n",
      " 52  KitchenQual    1460 non-null   object \n",
      " 53  TotRmsAbvGrd   1460 non-null   int64  \n",
      " 54  Functional     1460 non-null   object \n",
      " 55  Fireplaces     1460 non-null   int64  \n",
      " 56  FireplaceQu    770 non-null    object \n",
      " 57  GarageType     1379 non-null   object \n",
      " 58  GarageYrBlt    1379 non-null   float64\n",
      " 59  GarageFinish   1379 non-null   object \n",
      " 60  GarageCars     1460 non-null   int64  \n",
      " 61  GarageArea     1460 non-null   int64  \n",
      " 62  GarageQual     1379 non-null   object \n",
      " 63  GarageCond     1379 non-null   object \n",
      " 64  PavedDrive     1460 non-null   object \n",
      " 65  WoodDeckSF     1460 non-null   int64  \n",
      " 66  OpenPorchSF    1460 non-null   int64  \n",
      " 67  EnclosedPorch  1460 non-null   int64  \n",
      " 68  3SsnPorch      1460 non-null   int64  \n",
      " 69  ScreenPorch    1460 non-null   int64  \n",
      " 70  PoolArea       1460 non-null   int64  \n",
      " 71  PoolQC         7 non-null      object \n",
      " 72  Fence          281 non-null    object \n",
      " 73  MiscFeature    54 non-null     object \n",
      " 74  MiscVal        1460 non-null   int64  \n",
      " 75  MoSold         1460 non-null   int64  \n",
      " 76  YrSold         1460 non-null   int64  \n",
      " 77  SaleType       1460 non-null   object \n",
      " 78  SaleCondition  1460 non-null   object \n",
      " 79  SalePrice      1460 non-null   int64  \n",
      "dtypes: float64(3), int64(34), object(43)\n",
      "memory usage: 923.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('ames.csv', index_col=0)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386b42c1",
   "metadata": {},
   "source": [
    "As you can see, there are quite a lot of features to work with. It can be quite\n",
    "overwhelming, but we'll address this in the EDA section. There are also a\n",
    "significant number of null values to deal with, so we'll need to look at each\n",
    "of those."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addaa163",
   "metadata": {},
   "source": [
    "**Workflow:**\n",
    "\n",
    "I'll be following a modified version of the  CRISP-DM framework for this\n",
    "workflow, addressing:\n",
    "\n",
    "1. Business Understanding\n",
    "   1. Objectives\n",
    "   2. Situation\n",
    "   3. Metrics & Goals\n",
    "   4. Project Plan\n",
    "2. Data Understanding\n",
    "   1. Data Descriptions\n",
    "   2. Exploratory Data Analysis\n",
    "3. Data Preparation\n",
    "   1. Clean Data\n",
    "   2. Transform Data I: Feature Engineering\n",
    "   3. Transform Data II: Feature Encoding & Standardization\n",
    "4. Modeling\n",
    "   1. Select Modeling Techniques\n",
    "   2. Generate Test Design\n",
    "   3. Build & Train the Model\n",
    "5. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae482d8f",
   "metadata": {},
   "source": [
    "## Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cbb85e",
   "metadata": {},
   "source": [
    "### Objectives: What are we hoping to get out of this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cb4747",
   "metadata": {},
   "source": [
    "Given the nature of this data, the ideal outcome of this analysis is a pricing\n",
    "model that uses effective machine learning model(s) to predict how much a house\n",
    "will sell for. I intentionally use the word \"effective\" to describe the models,\n",
    "instead of something like \"advanced\" or \"complex,\" because we don't need to\n",
    "introduce unnecessary complexity just for the sake of it. However, if we find\n",
    "that the model fails to perform well on the dataset, we can start expanding the\n",
    "complexity of the models.\n",
    "\n",
    "There could be many reasons we are in need of this model. For instance, we\n",
    "could have a client in the real estate industry, an investor who is finding\n",
    "that they consistently overpay for properties by conventional methods. We could\n",
    "also be working for a lender who is looking to improve the appraisal portion of\n",
    "their underwriting process. Or, we could simply be an over-eager individual\n",
    "looking to purchase a home. Regardless of the purpose behind the objective,\n",
    "a house pricing predictor is clearly a useful tool if set up properly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364e2183",
   "metadata": {},
   "source": [
    "### Situation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfe742d",
   "metadata": {},
   "source": [
    "In short, what resources do we have at our disposal?\n",
    "\n",
    "Our primary source of information is the *Ames Housing Dataset*. The original\n",
    "dataset can be found on the American Statistical Association's [website][1]\n",
    "and a cleaned version can be found in [this repository][2]. The latter source\n",
    "also has a text file describing the various fields available to us. We'll come\n",
    "back to that later.\n",
    "\n",
    "Outside of these 2 files, we don't have a lot of other data available to us. In\n",
    "an industry case, we'd likely have multiple sources to extract data from,\n",
    "aggregating and joining across multiple database tables. We're both lucky and\n",
    "unlucky here: we don't have much work to do around data extraction, but we're\n",
    "also limited to the fields provided in the dataset. However, we still have a\n",
    "great number of features to work with.\n",
    "\n",
    "[1]: https://ww2.amstat.org/publications/jse/v19n3/decock/AmesHousing.txt\n",
    "[2]: https://github.com/melindaleung/Ames-Iowa-Housing-Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8b2e97",
   "metadata": {},
   "source": [
    "### Metrics & Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c455296e",
   "metadata": {},
   "source": [
    "*How do we measure our success, and where do we hope to land?*\n",
    "\n",
    "We have a range of options to measure performance on a regression model. Some\n",
    "that are most commonly used include mean squared error, mean absolute error,\n",
    "root mean squared error, and mean absolute percentage error. I'm selecting to\n",
    "go with **root mean squared error** for a couple reasons:\n",
    "\n",
    "- **Higher Penalty for Large Deviations:** Using a squared error (as opposed\n",
    "  to absolute or percentage) means we put extra emphasis on correctness. It's\n",
    "  better to be off by a few thousand here and there than to make a major\n",
    "  miscalculation on a home purchase.\n",
    "- **Explainability:** When we present this to non-technical stakeholders,\n",
    "  saying the model has an error of $8,000 is much better than saying it has\n",
    "  an error of 64,000,000. When using a squared error, this can only be achieved\n",
    "  by using the root-mean version of the error.\n",
    "\n",
    "With that said, I would like to get our model's error within 5% of the home\n",
    "values, meaning the target error amount will depend on the average sale price\n",
    "in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cccad47",
   "metadata": {},
   "source": [
    "### Project Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21dd5606",
   "metadata": {},
   "source": [
    "*What kind of technologies do we want to use, and how will we implement them?*\n",
    "\n",
    "Models\n",
    "\n",
    "- Linear Regression\n",
    "- Ridge Regression\n",
    "- Lasso\n",
    "- Elastic Net\n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "- Support Vector Machine\n",
    "- Gaussian Process Regression\n",
    "\n",
    "Techniques\n",
    "\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7e9a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "What kind of technologies do we want to use, and how will we implement them?\n",
    "\n",
    "We'll need to revisit this as we get further understanding of the data, but\n",
    "initially, we could make use of:\n",
    "\n",
    "- Logistic Regression\n",
    "- Naive-Bayes\n",
    "- k-Nearest Neighbors\n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "- Gradient-Boosted Trees\n",
    "- Ada Boost\n",
    "- Support Vector Machines\n",
    "\n",
    "Much of these are quickly available in the Scikit-Learn library. In addition,\n",
    "this library also provides tools for:\n",
    "\n",
    "- Train-Test splits\n",
    "- K-fold cross-validation\n",
    "- Stratified K-Fold cross-validation\n",
    "- Grid search CV\n",
    "- Accuracy metrics\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d981fd0d",
   "metadata": {},
   "source": [
    "## Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c19e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996b3551",
   "metadata": {},
   "source": [
    "### Data Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61159cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display columns 0-9, first 10 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e55eefd",
   "metadata": {},
   "source": [
    "> **Notes:**\n",
    ">\n",
    "> ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c89ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display columns 10-19, first 10 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ab8bc9",
   "metadata": {},
   "source": [
    "> **Notes:**\n",
    ">\n",
    "> ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ae57ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display columns 20-29, first 10 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ce22b0",
   "metadata": {},
   "source": [
    "> **Notes:**\n",
    ">\n",
    "> ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bff16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display columns 30-39, first 10 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4be02f",
   "metadata": {},
   "source": [
    "> **Notes:**\n",
    ">\n",
    "> ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8674d009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display columns 40-49, first 10 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883d5d43",
   "metadata": {},
   "source": [
    "> **Notes:**\n",
    ">\n",
    "> ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c92086f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display columns 50-59, first 10 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5905e3e5",
   "metadata": {},
   "source": [
    "> **Notes:**\n",
    ">\n",
    "> ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ebf4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display columns 60-69, first 10 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f9f1b9",
   "metadata": {},
   "source": [
    "> **Notes:**\n",
    ">\n",
    "> ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60c42fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display columns 70-79, first 10 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f992e028",
   "metadata": {},
   "source": [
    "> **Notes:**\n",
    ">\n",
    "> ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f86e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display data types\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf1366f",
   "metadata": {},
   "source": [
    "> **Notes:**\n",
    ">\n",
    "> ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52deb8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understand the Null Distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378a83c0",
   "metadata": {},
   "source": [
    "> **Notes:**\n",
    ">\n",
    "> ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfcb1c1",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a7a96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Formulate questions in the previous section and answer them here.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf3605c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7af1118",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd2a181",
   "metadata": {},
   "source": [
    "### Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6fa40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Address each of the data issues in the exploration section.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd524a3",
   "metadata": {},
   "source": [
    "### Transform Data I: Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771502c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create new features through combinations, etc.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bde340",
   "metadata": {},
   "source": [
    "### Transform Data II: Feature Encoding & Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430db19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Encode any fields and apply any standardizations (min-max, standard scaling, etc.)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65170098",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa5c739",
   "metadata": {},
   "source": [
    "### Select Modeling Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfe178b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "I hinted at this earlier, but there are several models we can apply here:\n",
    "\n",
    "1. Logistic Regression\n",
    "2. Naive-Bayes\n",
    "3. k-Nearest Neighbors\n",
    "4. Decision Tree\n",
    "5. Random Forest\n",
    "6. Gradient-Boosted Trees\n",
    "7. Ada Boost\n",
    "8. Support Vector Machines\n",
    "\n",
    "While we could go as far as looking at neural networks to introduce more\n",
    "sophisticated feature interactions, this may be overkill. However, if we don't\n",
    "get the performance we'd like out of these models, we can circle back to deep\n",
    "learning methods.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56b6e6a",
   "metadata": {},
   "source": [
    "### Generate Test Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a852424",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "As typical with machine learning, we'll need to split our data into training/\n",
    "testing data. From there, we can apply cross-validation to each model to\n",
    "determine the most optimal parameters for the model. A summary of our approach\n",
    "can be seen below. \n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://scikit-learn.org/stable/_images/grid_search_workflow.png\"\n",
    "    width=\"400px\"\n",
    "    height=\"240px\"\n",
    "    style=\"background: white; padding: 10px;\"\n",
    "  />\n",
    "</div>\n",
    "\n",
    "For measuring performance, we could look at an F1 score to account for\n",
    "precision/recall. However, since the overall survival rate isn't significantly\n",
    "different than the non-survival rate, a simple accuracy measure should suffice\n",
    "here.\n",
    "\n",
    "Finally, to tune the hyperparameters, we can use a grid search to find the\n",
    "optimal parameters. Note that, as the diagram above shows, the hyperparameter\n",
    "tuning will be done with a validation set, leaving the test set for the final\n",
    "model evaluation.\n",
    "\n",
    "We can store the model, grid search results, hyperparameters, and performance\n",
    "scores in a DataFrame for easy access.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de837a5",
   "metadata": {},
   "source": [
    "### Build & Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec750ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5e286e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Setup dataframe to store model information\n",
    "model_names = [\n",
    "    'AdaBoost',\n",
    "    'DecisionTree',\n",
    "    'NaiveBayes',\n",
    "    'GradientBoosted',\n",
    "    'KNN',\n",
    "    'LogisticRegression',\n",
    "    'RandomForest',\n",
    "    'SVC',\n",
    "]\n",
    "columns = ['Model', 'GridSearchResults', 'OptimalParams', 'Accuracy']\n",
    "models = pd.DataFrame(index=model_names, columns=columns)\n",
    "models\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b816c030",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def apply_grid_search(estimator: BaseEstimator, params: dict) -> pd.Series:\n",
    "    model = GridSearchCV(estimator, params, scoring='accuracy', n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    accuracy = model.score(X_test, y_test)\n",
    "    return pd.Series(dict(\n",
    "        Model=model.best_estimator_,\n",
    "        GridSearchResults=pd.DataFrame(model.cv_results_),\n",
    "        OptimalParams=model.best_params_,\n",
    "        Accuracy=accuracy,\n",
    "    ))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20f5cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
